





##### regionmetrics classes   2016-02-13 #####
# Transformation into functions

class CenterLocsRegionDistances(RegionDistances):
    """Region distances defined only by the distance of the representative
    points of each region.
    It can be cutted by a definition of a retriever neighbourhood of each
    representative point.
    """

    def compute_distances(self, sp_descriptor, store='network', elements=None,
                          symmetric=True, activated=None):
        """Function to compute the spatial distances between the regions.

        Parameters
        ----------
        sp_descriptor: sp_descriptor or tuple.
            the spatial descriptormodel object or the tuple of elements needed
            to build it (discretizor, locs, retriever, descriptormodel)
        store: optional, ['network', 'sparse', 'matrix']
            the type of object we want to store the relation metric.
        elements: array_like, list or None
            the regions we want to use for measure the metric distance between
            them.
        symmetric: boolean
            assume symmetric measure.
        activated: numpy.ndarray or None
            the location points we want to know if we use the regions non-empty
            or None if we want to use all of them.
        """
        ## 0. Compute variable needed
        self._symmetric = symmetric
        self._store = store
        # Sp descriptor management
        if type(sp_descriptor) == tuple:
            activated = sp_descriptor[1] if activated is not None else None
            regions_id, elements_i = get_regions4distances(sp_descriptor[0],
                                                           elements, activated)
            sp_descriptor = create_sp_descriptor_regionlocs(sp_descriptor,
                                                            regions_id,
                                                            elements_i)
            self._data = np.array(regions_id)
            self._data = self._data.reshape((self._data.shape[0], 1))
        else:
            regions, elements_i = get_regions4distances(sp_descriptor,
                                                        elements, activated)
            self._data = np.array(regions)
            self._data = self._data.reshape((self._data.shape[0], 1))

        ## 1. Computation of relations
        if type(sp_descriptor) == tuple:
            relations = pdist(sp_descriptor[0], sp_descriptor[1])
        else:
            relations = sp_descriptor.compute_net()[:, :, 0]
        if store == 'matrix':
            self.relations = relations
        elif store == 'sparse':
            self.relations = coo_matrix(relations)
        elif store == 'network':
            relations = coo_matrix(relations)
            self.relations = nx.from_scipy_sparse_matrix(relations)
            mapping = dict(zip(self.relations.nodes(), regions_id))
            self.relations = nx.relabel_nodes(self.relations, mapping)


class ContiguityRegionDistances(RegionDistances):
    """Region distances defined only by a contiguity measure defined in the
    discretization method.
    """

    def compute_distances(self, discretizor, store='network'):
        """Function to compute the spatial distances between the regions.
        """
        ## TODO: implement contiguity into the discretizor
        self._data = discretizor
        self._data = self._data.reshape((self._data.shape[0], 1))
        self.relations = discretizor.retrieve_contiguity_regions(store)


class AvgDistanceRegions(RegionDistances):
    """Average distance of points of the different regions.
    """

    def compute_distances(self, locs, discretizor, regretriever,
                          store='network', elements=None, activated=None):
        """Function to compute the spatial distances between regions.

        Parameters
        ----------
        locs: np.ndarray
            the locations of the elements.
        discretizor: pst.Discretization object
            the discretization information to transform locations into regions.
        store: optional, ['network', 'sparse', 'matrix']
            the type of object we want to store the relation metric.
        elements: array_like, list or None
            the regions we want to use for measure the metric distance between
            them.
        activated: numpy.ndarray or None
            the location points we want to know if we use the regions non-empty
            or None if we want to use all of them.
        """
        self._symmetric = True
        self._store = store

        regs = discretizor.discretize(locs)
        u_regs = np.unique(regs)
        n_regs = len(u_regs)
        self._data = u_regs.reshape((len(u_regs), 1))

        dts, iss, jss = [], [], []
        for i in xrange(len(u_regs)):
            locs_i = locs[regs == u_regs[i]]
            neighs_i, _ = regretriever.retrieve_neighs(u_regs[i])
            for j in range(len(neighs_i)):
                locs_j = locs[regs == neighs_i[j]]
                dists_j = np.where(neighs_i[j] == u_regs)[0]
                if len(locs_j):
                    dts.append(cdist(locs_i, locs_j).mean())
                    iss.append(i)
                    jss.append(dists_j[0])

        dts, iss, jss = np.hstack(dts), np.hstack(iss), np.hstack(jss)
        iss, jss = iss.astype(int), jss.astype(int)
        relations = coo_matrix((dts, (iss, jss)), shape=(n_regs, n_regs))

        if store == 'matrix':
            self.relations = relations
        elif store == 'sparse':
            self.relations = coo_matrix(relations)
        elif store == 'network':
            relations = coo_matrix(relations)
            self.relations = nx.from_scipy_sparse_matrix(relations)
            mapping = dict(zip(self.relations.nodes(), u_regs))
            self.relations = nx.relabel_nodes(self.relations, mapping)


class PointsNeighsIntersection(RegionDistances):
    """Region distances defined only by the intersection of neighbourhoods
    of the points belonged to each region.
    It is also applyable for the average distance between each points.
    """

    def compute_distances(self, sp_descriptor, store='network', elements=None,
                          symmetric=False, activated=None):
        """Function to compute the spatial distances between the regions.

        Parameters
        ----------
        sp_descriptor: sp_descriptor or tuple.
            the spatial descriptormodel object or the tuple of elements needed
            to build it (discretizor, locs, retriever, descriptormodel)
        store: optional, ['network', 'sparse', 'matrix']
            the type of object we want to store the relation metric.
        elements: array_like, list or None
            the regions we want to use for measure the metric distance between
            them.
        symmetric: boolean
            assume symmetric measure.
        activated: numpy.ndarray or None
            the location points we want to know if we use the regions non-empty
            or None if we want to use all of them.
        """
        ## 0. Needed variables
        # Sp descriptor management
        if type(sp_descriptor) == tuple:
            activated = sp_descriptor[1] if activated is not None else None
            regions_id, elements_i = get_regions4distances(sp_descriptor[0],
                                                           elements, activated)
            sp_descriptor = create_sp_descriptor_points_regs(sp_descriptor,
                                                             regions_id,
                                                             elements_i)
            self._data = np.array(regions_id)
            self._data = self._data.reshape((self._data.shape[0], 1))
        else:
            regions, elements_i = get_regions4distances(sp_descriptor,
                                                        elements, activated)
            self._data = np.array(regions)
            self._data = self._data.reshape((self._data.shape[0], 1))

        self._symmetric = symmetric
        self._store = store
        ## 1. Computation of relations
        relations = sp_descriptor.compute_net()[:, :, 0]
        #filter_relations(relations, self.data, elements)
        if store == 'matrix':
            self.relations = relations
        elif store == 'sparse':
            self.relations = coo_matrix(relations)
        elif store == 'network':
            relations = coo_matrix(relations)
            self.relations = nx.from_scipy_sparse_matrix(relations)
            mapping = dict(zip(self.relations.nodes(), regions_id))
            self.relations = nx.relabel_nodes(self.relations, mapping)




##### regionNeighbourhood   2016-01-13 ##### 

"""
Neighbourhood definition module
-------------------------------
This module contains the class which performs the neighbourhood retrieval from
spatial data regarding possible aggregation.
Deals with regions aggregation interface and retrieve region neighbourhood.


TODO
----
Join into the Region Retriever if it is possible.

"""

import numpy as np


class RegionNeighbourhood:
    """Retriever of regions given a discretization and a region.
    """

    data = None
    locs_r = []
    discretizors = []
    distance_reg = []
    regs = []
    reg_distances = []

    def __init__(self, locs, discretizors, distance_reg, precomputed=True):
        """
        Parameters
        ----------
        locs: numpy.ndarray
            the location coordinates.
        discretizors: list of spatialdisc objects or list of numpy.ndarray
            a list of discretization measures.
        distance_reg: list of regiondistances objects
            the information to compute the distance between regions.
        """
        m = len(discretizors)
        ## Location
        self.data = locs
        ## Discretization by regions
        if type(discretizors[0]) != np.ndarray:
            self.locs_r = [discretizors.discretize(locs, m) for i in range(m)]
            self.discretizors = None
        else:
            self.locs_r = discretizors
        self.regs = [np.unique(self.locs_r[m]) for i in range(m)]
        self.precomputed = precomputed
        ## Region distances
        self.distance_reg = distance_reg

    def discretize(self, i_locs, i_disc=0):
        """Discretization of location to retrieve region of which the point
        belongs.

        Parameters
        ----------
        i_locs: int, numpy.ndarray
            the information of the points to discretize.
        i_disc: int
            the discretization we want to apply.

        Returns
        -------
        discs_i: int or numpy.ndarray
            the regions of each point discretized.

        """
        if self.locs_r is None:
            discs_i = self.discretizors[i_disc].discretize(i_locs)
        else:
            discs_i = self.locs_r[i_disc][i_locs]
        return discs_i
###################################################################################
###################################################################################
###################################################################################
###################################################################################

##### aux_regionmetrics   2016-01-12
def format_elements(elements, discretizor, retriever):
    """Format elements."""
    # Elements management
    if elements is True:
        # Filter by activated regions
        elements = discretizor.discretize(retriever.retriever.data)
        regions_id = np.unique(elements)
    elif elements is False:
        if type(retriever) == str:
            regions_id = np.unique(discretizor.get_regions_id())
        else:
            if retriever.tags is None:
                regions_id = np.arange(retriever.retriever.data.shape[0])
            else:
                regions_id = np.array(retriever.tags)
    elif type(elements) in [list, np.ndarray]:
        regions_id = np.unique(elements)
    # Transform elements into elements_i

    def compute_contiguity(self, retriever, locs, info_i):
        """Compute contiguity using the locations and a retriever.

        TODO
        ----
        Use correlation measure!!!!!
        """
        ## 0. Prepare inputs
        sh = locs.shape
        locs = locs if len(sh) > 1 else locs.reshape((1, sh[0]))
        ret = retriever(locs)
        regions_u = self.regions_id.unique()
        n_reg_u = regions_u.shape[0], regions_u.shape[0]
        regions_counts = np.zeros(n_reg_u)
        region_coincidences = np.zeros((n_reg_u, n_reg_u))
        ## 1. Compute matrix of coincidences
        regions = self.discretize(locs)
        for i in xrange(locs.shape[0]):
            r = regions[i]
            i_r = np.where(regions_u == r)
            neighs, dist = ret.retrieve_neighs(locs[i, :], info_i[i], True)
            regs = regions[neighs]
            i_regs = np.array([rs == regions_u for rs in regs])
            weights = compute_weigths(regs, dist)
            region_coincidences[i_r, i_regs] += weights
        contiguity = compute_measure(region_coincidences, regions_counts)
        return contiguity


def sparse_from_listaregneighs(lista, u_regs, symmetric):
    """Sparse representation matrix from a list of tuples of indices and
    values.
    """
    sh = (u_regs.shape[0], u_regs.shape[0])
    lista = np.array(lista)
    dts, iss, jss = lista[:, 2], lista[:, 0], lista[:, 1]
#    dts, iss, jss = [], [], []
#    for i in xrange(len(lista)):
#        print lista[i]
#        n_neigh = lista[i][1].shape[0]
#        for j in range(n_neigh):
#            dts.append(lista[i][0])
#            iss.append(lista[i][1][j])
#            jss.append(lista[i][2][j])
#            if symmetric:
#                dts.append(lista[i][0])
#                iss.append(lista[i][2][j])
#                jss.append(lista[i][1][j])
    dts, iss, jss = np.array(dts), np.array(iss), np.array(jss)
    relations = coo_matrix((dts, (iss, jss)), shape=sh)
    return relations




def regions_relation_points(locs, regions, retriever, info_ret):
    """Function which computes the spatial relations between regions
    considering the shared neighbourhoods of their points.

    TODO
    ----
    - Normalization coincidence

    """

    ## 0. Compute needed variables
    regs = np.unique(regions)
    count_reg = Counter(regions)
    n_reg = regs.shape[0]
    map_reg = dict(zip(regs, range(regs.shape[0])))

    ## 1. Count coincidences
    coincidence = np.zeros((n_reg, n_reg))
    for i in xrange(locs.shape[0]):
        neighs = retriever.retrieve_neighs(locs[i, :], info_ret[i], False)[0]
        count_neighs = Counter(regs[neighs])
        t_neighs = count_neighs.keys()
        for j_nei in t_neighs:
            res = count_neighs[j_nei]/count_reg[j_nei]

        for j in range(len(neighs)):
            coincidence[map_reg[regions[i]], map_reg[regions[neighs[j]]]] += 1.
    ## 2. Normalization of coincidences

    return coincidence
